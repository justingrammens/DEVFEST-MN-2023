{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open AI Function Calling -- WHY?\n",
    "\n",
    "Even with all the good stuff, the OpenAI API was a nightmare for the developers and engineers. Why? They are accustomed to working with structured data types, and working with unstructured data like string is hard.\n",
    "\n",
    "To get consistent results, developers have to use regular expressions (RegEx) or prompt engineering to extract the information from the text string.\n",
    "\n",
    "This is where OpenAI's function calling capability comes in. It allows GPT-3.5 and GPT-4 models to take user-defined functions as input and generate structure output. With this, you don't need to write RegEx or perform prompt engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description = \"Susan Johnson is a sophomore majoring in computer science at Stanford University. He is Asian American and has a 3.8 GPA. David is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after graduating.\"\n",
    "\n",
    "# A simple prompt to extract information from \"student_description\" in a JSON format.\n",
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "json_object = json.loads(response.choices[0].message.content)\n",
    "print(json.dumps(json_object, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_2_description=\"Ravish Kurpad is a sophomore majoring in computer science at the University of Michigan. He is South Asian Indian American and has a 3.7 GPA. Ravi is an active member of the university's Chess Club and the South Asian Student Association. He hopes to pursue a career in software engineering after graduating.\"\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "json_object = json.loads(response.choices[0].message.content)\n",
    "print(json.dumps(json_object, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE OUTPUT IS NOT CONSISTENT :(\n",
    "Grades of the first student is “3.8 GPA”, whereas in the second student prompt, we got only the number “3.7”. It is a huge deal when you are building a stable system.\n",
    "Instead of returning one club, it has returned the list of clubs joined by Ravish. It is also different from the first student.\n",
    "\n",
    "OpenAI Functions to the Rescue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_custom_functions = [\n",
    "    {\n",
    "        'name': 'extract_student_info',\n",
    "        'description': 'Get the student information from the body of the input text',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'name': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Name of the person'\n",
    "                },\n",
    "                'major': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Major subject.'\n",
    "                },\n",
    "                'school': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The university name.'\n",
    "                },\n",
    "                'grades': {\n",
    "                    'type': 'integer',\n",
    "                    'description': 'GPA of the student.'\n",
    "                },\n",
    "                'club': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'School club for extracurricular activities. '\n",
    "                }\n",
    "                \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_description = [student_1_description,student_2_description]\n",
    "for sample in student_description:\n",
    "    response = openai.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        messages = [{'role': 'user', 'content': sample}],\n",
    "        functions = student_custom_functions,\n",
    "        function_call = 'auto'\n",
    "    )\n",
    "\n",
    "    # Loading the response as a JSON object\n",
    "    json_object = json.loads(response.choices[0].message.function_call.arguments)\n",
    "    print(json.dumps(json_object, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NICE!\n",
    "As we can see, we got uniform output. We even got grades in numeric instead of string. Consistent output is essential for creating bug-free AI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Custom Functions\n",
    "\n",
    "You can add multiple custom functions to the chat completion function. In this section, we will see the magical capabilities of OpenAI API and how it automatically selects the correct function and returns the right arguments.\n",
    "\n",
    "In the Python list of the dictionary, we will add another function called “extract_school_info,” which will help us extract university information from the text.\n",
    "\n",
    "To achieve this, you have to add another dictionary of a function with name, description, and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_functions = [\n",
    "    {\n",
    "        'name': 'extract_student_info',\n",
    "        'description': 'Get the student information from the body of the input text',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'name': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Name of the person'\n",
    "                },\n",
    "                'major': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Major subject.'\n",
    "                },\n",
    "                'school': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The university name.'\n",
    "                },\n",
    "                'grades': {\n",
    "                    'type': 'integer',\n",
    "                    'description': 'GPA of the student.'\n",
    "                },\n",
    "                'club': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'School club for extracurricular activities. '\n",
    "                }\n",
    "                \n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'extract_school_info',\n",
    "        'description': 'Get the school information from the body of the input text',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'name': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Name of the school.'\n",
    "                },\n",
    "                'ranking': {\n",
    "                    'type': 'integer',\n",
    "                    'description': 'QS world ranking of the school.'\n",
    "                },\n",
    "                'country': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Country of the school.'\n",
    "                },\n",
    "                'no_of_students': {\n",
    "                    'type': 'integer',\n",
    "                    'description': 'Number of students enrolled in the school.'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_1_description = \"Stanford University is a private research university located in Stanford, California, United States. It was founded in 1885 by Leland Stanford and his wife, Jane Stanford, in memory of their only child, Leland Stanford Jr. The university is ra/nked #5 in the world by QS World University Rankings. It has over 17,000 students, including about 7,600 undergraduates and 9,500 graduates23. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = [student_1_description, school_1_description]\n",
    "for i in description:\n",
    "    response = openai.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        messages = [{'role': 'user', 'content': i}],\n",
    "        functions = custom_functions,\n",
    "        function_call = 'auto'\n",
    "    )\n",
    "\n",
    "    # Loading the response as a JSON object\n",
    "    json_object = json.loads(response.choices[0].message.function_call.arguments)\n",
    "    print(json.dumps(json_object, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "The GPT-3.5-Turbo model has automatically selected the correct function for different description types. We get perfect JSON output for the student and the school!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application Using Function Calling\n",
    "\n",
    "In this section, we will build a stable text summarizer that will summarize the school and student information in a certain way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_student_info(name, major, school, grades, club):\n",
    "    \n",
    "    \"\"\"Get the student information\"\"\"\n",
    "\n",
    "    return f\"{name} is majoring in {major} at {school}. He has {grades} GPA and he is an active member of the university's {club}.\"\n",
    "\n",
    "def extract_school_info(name, ranking, country, no_of_students):\n",
    "    \n",
    "    \"\"\"Get the school information\"\"\"\n",
    "\n",
    "    return f\"{name} is located in the {country}. The university is ranked #{ranking} in the world with {no_of_students} students.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we will create a prompt to extract information from the student description and the school description.\n",
    "\n",
    "# Create the Python list, which consists of student one description, random prompt, and school one description. The random prompt is added to validate the automatic function calling mechanic.\n",
    "# We will generate the response using each text in the `descriptions` list.\n",
    "# If a function call is used, we will get the name of the function and, based on it, apply the relevant arguments to the function using the response. Otherwise, return the normal response.\n",
    "# Print the outputs of all three samples.\n",
    "\n",
    "descriptions = [\n",
    "    student_1_description, \n",
    "    \"Who was a Abraham Lincoln?\",\n",
    "    school_1_description\n",
    "                ]\n",
    "for i, sample in enumerate(descriptions):\n",
    "    response = openai.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        messages = [{'role': 'user', 'content': sample}],\n",
    "        functions = custom_functions,\n",
    "        function_call = 'auto'\n",
    "    )\n",
    "    \n",
    "    response_message = response.choices[0].message\n",
    "    \n",
    "    if response_message.function_call:\n",
    "        \n",
    "        # Which function call was invoked\n",
    "        function_called = response_message.function_call.name\n",
    "        \n",
    "        # Extracting the arguments\n",
    "        function_args  = json.loads(response_message.function_call.arguments)\n",
    "        \n",
    "        # Function names\n",
    "        available_functions = {\n",
    "            \"extract_school_info\": extract_school_info,\n",
    "            \"extract_student_info\": extract_student_info\n",
    "        }\n",
    "        \n",
    "        fuction_to_call = available_functions[function_called]\n",
    "        response_message = fuction_to_call(*list(function_args .values()))\n",
    "        \n",
    "    else:\n",
    "        response_message = response_message.content\n",
    "    \n",
    "    print(f\"\\nSample#{i+1}\\n\")\n",
    "    print(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
